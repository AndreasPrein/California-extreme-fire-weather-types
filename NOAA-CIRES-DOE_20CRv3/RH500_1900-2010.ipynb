{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RH500_1900-2010.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    File name: RH500_1900-2010.ipynb\\n    Author: Andreas Prein\\n    E-mail: prein@ucar.edu\\n    Date created: 23.07.2020\\n    Date last modified: 23.07.2020\\n\\n    ##############################################################\\n    Purpos:\\n\\n    1) Reads in T2 and DT2 variables from the ERA-20C\\n\\n    2) Calculate RH\\n\\n    3) store the data as NetCDF\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    File name: RH500_1900-2010.ipynb\n",
    "    Author: Andreas Prein\n",
    "    E-mail: prein@ucar.edu\n",
    "    Date created: 23.07.2020\n",
    "    Date last modified: 23.07.2020\n",
    "\n",
    "    ##############################################################\n",
    "    Purpos:\n",
    "\n",
    "    1) Reads in T2 and DT2 variables from the ERA-20C\n",
    "\n",
    "    2) Calculate RH\n",
    "\n",
    "    3) store the data as NetCDF\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import rrule\n",
    "import datetime\n",
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "import sys, traceback\n",
    "import dateutil.parser as dparser\n",
    "import string\n",
    "from pdb import set_trace as stop\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "from mpl_toolkits import basemap\n",
    "import pickle\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib as mpl\n",
    "import pylab as plt\n",
    "import random\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pylab import *\n",
    "import string\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "import shapefile\n",
    "import shapely.geometry\n",
    "# import descartes\n",
    "import shapefile\n",
    "import math\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from scipy import spatial\n",
    "import scipy.ndimage\n",
    "import matplotlib.path as mplPath\n",
    "from scipy.interpolate import interp1d\n",
    "import time\n",
    "from math import atan2, degrees, pi\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "# import SkewT\n",
    "import csv\n",
    "import pygrib\n",
    "from scipy import interpolate\n",
    "import wrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________________________________________________\n",
    "# ________________________________________________________________________\n",
    "#             USER INPUT SECTION\n",
    "\n",
    "DataDir='/glade/campaign/mmm/c3we/prein/NCEP-20C/daymean/'\n",
    "SaveDir='/glade/campaign/mmm/c3we/prein/NCEP-20C/daymean/RH500/'\n",
    "if not os.path.exists(SaveDir):\n",
    "    os.makedirs(SaveDir)\n",
    "Vars=['T500','Q500']\n",
    "FinVar='RH500'\n",
    "ConstantVars='/gpfs/fs1/collections/rda/data/ds131.3/anl/anl_mean_2015_VGRD_pres.nc'\n",
    "\n",
    "rgdTime = pd.date_range(datetime.datetime(1900, 1, 1,0), end=datetime.datetime(2015, 12, 31,23), freq='d')\n",
    "YYYYall = np.unique(rgdTime.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________________________________________________________\n",
    "# ________________________________________________________________________\n",
    "#              READ IN THE COORDINATES\n",
    "ncid=Dataset(ConstantVars, mode='r')\n",
    "rgrLat=np.squeeze(ncid.variables['latitude'][:])\n",
    "rgrLon=np.squeeze(ncid.variables['longitude'][:])\n",
    "ncid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    process 1900\n",
      "    process 1901\n",
      "    process 1902\n",
      "    process 1903\n",
      "    process 1904\n",
      "    process 1905\n",
      "    process 1906\n",
      "    process 1907\n",
      "    process 1908\n",
      "    process 1909\n",
      "    process 1910\n",
      "    process 1911\n",
      "    process 1912\n",
      "    process 1913\n",
      "    process 1914\n",
      "    process 1915\n",
      "    process 1916\n",
      "    process 1917\n",
      "    process 1918\n",
      "    process 1919\n",
      "    process 1920\n",
      "    process 1921\n",
      "    process 1922\n",
      "    process 1923\n",
      "    process 1924\n",
      "    process 1925\n",
      "    process 1926\n",
      "    process 1927\n",
      "    process 1928\n",
      "    process 1929\n",
      "    process 1930\n",
      "    process 1931\n",
      "    process 1932\n",
      "    process 1933\n",
      "    process 1934\n",
      "    process 1935\n",
      "    process 1936\n",
      "    process 1937\n",
      "    process 1938\n",
      "    process 1939\n",
      "    process 1940\n",
      "    process 1941\n",
      "    process 1942\n",
      "    process 1943\n",
      "    process 1944\n"
     ]
    }
   ],
   "source": [
    "for yy in range(len(YYYYall)):\n",
    "    print('    process '+str(YYYYall[yy]))\n",
    "    for me in range(80):\n",
    "        T_file=DataDir+Vars[0]+'/'+Vars[0]+'.'+str(YYYYall[yy])+'_mem'+str(me+1).zfill(3)+'.nc'\n",
    "        Q_file=DataDir+Vars[1]+'/'+Vars[1]+'.'+str(YYYYall[yy])+'_mem'+str(me+1).zfill(3)+'.nc'\n",
    "        T_Filename=T_file.split('/')[-1]\n",
    "        File_fin=SaveDir+'/'+T_Filename.replace(Vars[0], FinVar)\n",
    "        File=SaveDir+T_Filename.replace(Vars[0], FinVar)+'_copy'\n",
    "        if os.path.exists(File_fin) == 0:\n",
    "            if not os.path.exists(SaveDir):\n",
    "                os.makedirs(SaveDir)\n",
    "#             print( '    '+File_fin)\n",
    "            ncid=Dataset(T_file, mode='r')\n",
    "            rgrT=np.squeeze(ncid.variables[Vars[0]][:])\n",
    "            time_act=np.squeeze(ncid.variables['time'][:])\n",
    "            ncid.close()\n",
    "            ncid=Dataset(Q_file, mode='r')\n",
    "            rgrQ=np.squeeze(ncid.variables[Vars[1]][:])\n",
    "            ncid.close()\n",
    "            \n",
    "            rgrP = np.copy(rgrQ); rgrP[:] = 50000.\n",
    "            RH_vals = wrf.rh(rgrQ, rgrP , rgrT, meta=False)\n",
    "\n",
    "            # ________________________________________________________________________\n",
    "            # write the netcdf\n",
    "#             print( '        ----------------------')\n",
    "#             print( '        Save data to '+File_fin)\n",
    "            root_grp = Dataset(File, 'w', format='NETCDF4')\n",
    "            # dimensions\n",
    "            root_grp.createDimension('time', None)\n",
    "            root_grp.createDimension('rlon', rgrLon.shape[0])\n",
    "            root_grp.createDimension('rlat', rgrLat.shape[0])\n",
    "            # variables\n",
    "            lat = root_grp.createVariable('lat', 'f4', ('rlat',))\n",
    "            lon = root_grp.createVariable('lon', 'f4', ('rlon',))\n",
    "            time = root_grp.createVariable('time', 'f8', ('time',))\n",
    "            RH = root_grp.createVariable(FinVar, 'f4', ('time','rlat','rlon',),fill_value=-99999)\n",
    "\n",
    "            time.calendar = \"proleptic_gregorian\"\n",
    "            time.units = \"hours since 1900-1-1 00:00:00\"\n",
    "            time.standard_name = \"time\"\n",
    "            time.long_name = \"time\"\n",
    "\n",
    "            lon.standard_name = \"longitude\"\n",
    "            lon.long_name = \"longitude\"\n",
    "            lon.units = \"degrees_east\"\n",
    "\n",
    "            lat.standard_name = \"latitude\"\n",
    "            lat.long_name = \"latitude\"\n",
    "            lat.units = \"degrees_north\"\n",
    "\n",
    "            RH.standard_name = \"500 hPa relative humidity\"\n",
    "            RH.long_name = \"500 hPa relative humidity\"\n",
    "            RH.units = \"%\"\n",
    "\n",
    "            # write data to netcdf\n",
    "            lat[:]=rgrLat\n",
    "            lon[:]=rgrLon\n",
    "            RH[:]=RH_vals\n",
    "            time[:]=time_act\n",
    "            root_grp.close()\n",
    "\n",
    "            # compress the netcdf file\n",
    "            pp = subprocess.Popen(\"nccopy -k 4 -d 1 -s \"+File+' '+File_fin, shell=True)\n",
    "            pp.wait()\n",
    "            subprocess.Popen(\"rm  \"+File, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
